# Curso de Apache Airflow

## O que é Airflow:

O **Apache Airflow** é uma plataforma de orquestração de fluxo de trabalho (workflow) open-source, projetada para facilitar a automação, agendamento e monitoramento de processos de dados complexos e sequenciais.

## Por que usar Airflow:

O **Airflow** oferece uma maneira flexível e extensível de definir, agendar e executar fluxos de trabalho. Ele é particularmente útil em ambientes onde tarefas precisam ser executadas de maneira programada e escalável, proporcionando visibilidade e controle sobre o processo de execução.

## Trilha do Conhecimento:

1. **Conhecer a Arquitetura do Airflow:**
   - Entender os componentes principais que compõem a arquitetura do Airflow.

2. **Aprender Fundamentos de DAGs e Tasks:**
   - Familiarizar-se com conceitos-chave como *Directed Acyclic Graphs (DAGs)* e tarefas (*Tasks*).

3. **Construir suas Próprias DAGs:**
   - Criar e gerenciar fluxos de trabalho personalizados usando DAGs.

4. **Implementar DAGs com Operadores:**
   - Utilizar uma variedade de operadores, incluindo `PythonOperator`, `PostgresOperator`, entre outros.

5. **Entender e Aplicar Conceitos Avançados:**
   - Explorar conceitos como Pools, Variáveis, branchs e Dataset.

6. **Criar Sensores em Airflow:**
   - Implementar sensores para monitorar condições antes da execução de tarefas.

7. **Conhecer e Implementar Regras de Triggers:**
   - Utilizar regras de acionamento para controle avançado de execução.

8. **Trocar Dados utilizando XCom:**
   - Compartilhar dados entre tarefas usando o mecanismo XCom.

9. **Enviar E-mails em Caso de Falhas ou em Tarefas Específicas:**
   - Configurar alertas de e-mail para notificações em casos de falhas ou eventos específicos.

10. **Entender e Criar Hooks:**
    - Utilizar hooks para interação com sistemas externos.

11. **Compreender as Principais Configurações do Airflow:**
    - Explorar e configurar parâmetros importantes do Airflow.

12. **Estudar os Tipos de Executors e Suas Características:**
    - Conhecer os diferentes tipos de executores e escolher o mais adequado para os requisitos específicos.

13. **Conectar e Atualizar Bancos de Dados:**
    - Integrar o Airflow com bancos de dados, permitindo operações de leitura e escrita.

Este curso abrange desde os conceitos fundamentais até tópicos avançados, proporcionando uma compreensão abrangente do Apache Airflow e suas capacidades de automação de fluxos de trabalho. Prepare-se para aprimorar suas habilidades em orquestração de dados e automação de processos com esta trilha educativa.

## Agradecimentos
Meu muito obrigado ao professor **Fernando Amaral**  pela didática 
https://www.linkedin.com/in/fernando-amaral
https://www.eia.ai/
